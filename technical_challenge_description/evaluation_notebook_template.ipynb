{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Notebook Template "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> <font color='red'> WARNING : </font>  </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> No matter which approach you've chosen, you need to re-install any custom packages you had to install to make your code work ! </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Install your packages below: </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/Total-RD/pymgrid/\n",
    "## Other packages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the section below, you must run your methodology for solving the problem from start to finish :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('building_1.pkl', 'rb') as f:\n",
    "    building_1 = pickle.load(f)\n",
    "\n",
    "with open('building_2.pkl', 'rb') as f:\n",
    "    building_2 = pickle.load(f)\n",
    "    \n",
    "with open('building_3.pkl', 'rb') as f:\n",
    "    building_3 = pickle.load(f)\n",
    "\n",
    "buildings = [building_1, building_2, building_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Evaluation for Rule Based Approaches </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using Rule Based Algorithms, here is what your submitted code should feature no matter what "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1) Import all used libraries and scripts here </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # Necessary to evaluate frugality\n",
    "import json # Necessary to export your results\n",
    "## Other packages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2) Implementation of the rules that generate control dictionaries </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXAMPLE FOR A NAIVE RULE BASED STRATEGY\n",
    "\"\"\"\n",
    "def naive_rule_based_strategy(building):\n",
    "    building_data = building.get_updated_values()\n",
    "\n",
    "    total_building_cost = 0\n",
    "\n",
    "    while building.done == False:\n",
    "        load = building_data['load']\n",
    "        pv = building_data['pv']\n",
    "        capa_to_charge = building_data['capa_to_charge']\n",
    "        capa_to_dischare = building_data['capa_to_discharge']\n",
    "\n",
    "        p_disc = max(0, min(load-pv, capa_to_dischare, building.battery.p_discharge_max))\n",
    "        p_char = max(0, min(pv-load, capa_to_charge, building.battery.p_charge_max))\n",
    "\n",
    "        if load - pv >=  0:\n",
    "\n",
    "            control_dict = {'battery_charge': 0,\n",
    "                                'battery_discharge': p_disc,\n",
    "                                'grid_import': max(0, load-pv-p_disc),\n",
    "                                'grid_export':0,\n",
    "                                'pv_consummed': min(pv, load),\n",
    "                           }\n",
    "\n",
    "\n",
    "        if load - pv <  0:\n",
    "\n",
    "            control_dict = {'battery_charge': p_char,\n",
    "                                'battery_discharge': 0,\n",
    "                                'grid_import': 0,\n",
    "                                'grid_export': max(0,pv-load-p_char),#abs(min(load-pv,0)),\n",
    "                                'pv_consummed': min(pv, load+p_char),\n",
    "                           }\n",
    "\n",
    "        building_data = building.run(control_dict)\n",
    "        total_building_cost += building.get_cost()\n",
    "    \n",
    "    return total_building_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 3) Run of the rules on the Test environment </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rule based methods have no \"training\" as such, this means Training CPU Time will always be 0 and only\n",
    "Test CPU Time will represent frugality\n",
    "\"\"\"\n",
    "\n",
    "eval_start = time.process_time()\n",
    "\n",
    "total_building_costs = []\n",
    "\n",
    "for building in buildings:\n",
    "\n",
    "    building.reset(testing = True)\n",
    "\n",
    "    total_building_cost = naive_rule_based_strategy(building)\n",
    "    total_building_costs.append(total_building_cost)\n",
    "\n",
    "eval_end = time.process_time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost_building_1 = total_building_costs[0]\n",
    "total_cost_building_2 = total_building_costs[1]\n",
    "total_cost_building_3 = total_building_costs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frugality = eval_end - eval_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 4) Store & Export Results in JSON format </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {\n",
    "    \"building_1_performance\" : total_cost_building_1,\n",
    "    \"building_2_performance\" : total_cost_building_2,\n",
    "    \"building_3_performance\" : total_cost_building_3,\n",
    "    \"frugality\" : frugality,\n",
    "}\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = ## Enter Team name here\n",
    "\n",
    "with open(team_name + '.txt', 'w') as json_file:\n",
    "    json.dump(final_results, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Evaluation for \"Simple\" Reinforcement Learning based approaches <h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='red'> <b> Be careful, the rewards returned by the Gym environment are negative ! Don't forget to multiply by -1 the total reward as the Profitability you will need to submit needs to be positive ! </b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1) Import all used libraries and scripts here </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # Necessary to evaluate frugality\n",
    "import json # Necessary to export your results\n",
    "import DiscreteEnvironment as DiscreteEnvironment # Imposed Discrete Environment\n",
    "import numpy as np\n",
    "\n",
    "## Other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2) Agent & Environment Setup before your training </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_environments = [\n",
    "    DiscreteEnvironment.Environment(env_config={'building':buildings[i]}) for i in range(3)\n",
    "]\n",
    "\"\"\"\n",
    "Agent, potential Q-Table & other necessary setup code here \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 3) Training of the agent </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_start = time.process_time()\n",
    "\n",
    "\"\"\"\n",
    "Training code\n",
    "\"\"\"\n",
    "\n",
    "train_end = time.process_time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frugality = train_end - train_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 4) Test of the agent </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Below is an example for a Random Agent \n",
    "\n",
    "Note :\n",
    "* To make your work as reproductible as possible, have a full-greedy approach (no exploration) on the test buildings\n",
    "* If your algorithm has some unavoidable randomness, consider running it for many loops and return a\n",
    "  mean profitability and mean frugality\n",
    "  \n",
    "\"\"\"\n",
    "\n",
    "test_start = time.process_time()\n",
    "total_cost = [0,0,0]\n",
    "\n",
    "for i,building_env in enumerate(building_environments):\n",
    "    \n",
    "    obs = building_env.reset(testing=True)\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = np.random.randint(building_env.action_space.n)\n",
    "        obs, reward, done, info = building_env.step(action)\n",
    "        total_cost[i]+=reward\n",
    "\n",
    "test_end = time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frugality = test_end - test_start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 5) Store & Export Results in JSON format </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {\n",
    "    \"building_1_performance\" : total_cost[0],\n",
    "    \"building_2_performance\" : total_cost[1],\n",
    "    \"building_3_performance\" : total_cost[2],\n",
    "    \"frugality\" : train_frugality + test_frugality,\n",
    "}\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = ## Enter Team name here\n",
    "\n",
    "with open(team_name + '.txt', 'w') as json_file:\n",
    "    json.dump(final_results, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Evaluation for Deep Reinforcement Learning based approaches <h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='red'> <b> Be careful, the rewards returned by the Gym environment are negative ! Don't forget to multiply by -1 the total reward as the Profitability you will need to submit needs to be positive ! </b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1) Import all used libraries and scripts here </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # Necessary to evaluate frugality\n",
    "from pymgrid.Environments.pymgrid_cspla import MicroGridEnv # Imposed Environment\n",
    "import numpy as np\n",
    "\n",
    "## Import your favourite Deep Learning library for RL and other packages here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2) Agent & Environment Setup before your training </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Below is an environment initialization without a Deep RL library, the code can vary depending on which library you \n",
    "use\n",
    "\"\"\"\n",
    "building_environments = [MicroGridEnv(env_config={'microgrid':buildings[i]}) for i in range(3)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 3) Training of the agent </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = time.process_time()\n",
    "\n",
    "\"\"\"\n",
    "Train code\n",
    "\"\"\"\n",
    "\n",
    "train_end = time.process_time()\n",
    "train_frugality = train_end - train_start\n",
    "\n",
    "\n",
    "frugality = train_frugality + test_frugality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 4) Test of the agent </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Below is an example for a Random Agent \n",
    "\n",
    "Note :\n",
    "* To make your work as reproductible as possible, have a full-greedy approach (no exploration) on the test buildings\n",
    "* If your algorithm has some unavoidable randomness, consider running it for many loops and return a\n",
    "  mean profitability and mean frugality\n",
    "  \n",
    "\"\"\"\n",
    "\n",
    "test_start = time.process_time()\n",
    "\n",
    "\n",
    "test_start = time.process_time()\n",
    "total_cost = [0,0,0]\n",
    "\n",
    "for i,building_env in enumerate(building_environments):\n",
    "    \n",
    "    obs = building_env.reset(testing=True)\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = np.random.randint(building_env.action_space.n)\n",
    "        obs, reward, done, info = building_env.step(action)\n",
    "        total_cost[i]+=reward\n",
    "\n",
    "test_end = time.process_time()\n",
    "\n",
    "test_frugality = test_end - test_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 5) Store & Export Results in JSON format </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {\n",
    "    \"building_1_performance\" : total_cost[0],\n",
    "    \"building_2_performance\" : total_cost[1],\n",
    "    \"building_3_performance\" : total_cost[2],\n",
    "    \"frugality\" : train_frugality + test_frugality,\n",
    "}\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = ## Enter Team name here\n",
    "\n",
    "with open(team_name + '.txt', 'w') as json_file:\n",
    "    json.dump(final_results, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> For Optimisation based approaches <h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the README and the Getting Started Notebook, the evaluation depends heavily on how you formulate the problem, no template can be given for this familly of methods "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "hiparis",
   "language": "python",
   "name": "hiparis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
