{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pymgrid import MicrogridGenerator as mg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from IPython.core.debugger import set_trace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\"\"\"\n",
    "The buildings mentionned below are specific to the hackathon and are not available in this repo.\n",
    "You can replace them with any MicroGrid object generated from pymgrid\n",
    "\"\"\"\n",
    "\n",
    "with open('building_1.pkl', 'rb') as f:\n",
    "    building_1 = pickle.load(f)\n",
    "\n",
    "with open('building_2.pkl', 'rb') as f:\n",
    "    building_2 = pickle.load(f)\n",
    "    \n",
    "with open('building_3.pkl', 'rb') as f:\n",
    "    building_3 = pickle.load(f)\n",
    "\n",
    "buildings = [building_1, building_2, building_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[0].reset()\n",
    "buildings[1].reset()\n",
    "buildings[2].reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> A naive example to get your started can be found below </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_rule_based_strategy(building):\n",
    "    \n",
    "    building_data = building.get_updated_values()\n",
    "    datas=[]\n",
    "\n",
    "    total_building_cost = []\n",
    "    total_building_co2 = 0\n",
    "    while building.done == False:\n",
    "        load = building_data['load']\n",
    "        pv = building_data['pv']\n",
    "        capa_to_charge = building_data['capa_to_charge']\n",
    "        capa_to_dischare = building_data['capa_to_discharge']\n",
    "\n",
    "        p_disc = max(0, min(load-pv, capa_to_dischare, building.battery.p_discharge_max))\n",
    "        p_char = max(0, min(pv-load, capa_to_charge, building.battery.p_charge_max))\n",
    "\n",
    "        if load - pv >=  0:\n",
    "\n",
    "            control_dict = {'battery_charge': 0,\n",
    "                                'battery_discharge': p_disc,\n",
    "                                'grid_import': max(0, load-pv-p_disc),\n",
    "                                'grid_export':0,\n",
    "                                'pv_consummed': min(pv, load),\n",
    "                                'genset':1,\n",
    "                           }\n",
    "\n",
    "\n",
    "        if load - pv <  0:\n",
    "\n",
    "            control_dict = {'battery_charge': p_char,\n",
    "                                'battery_discharge': 0,\n",
    "                                'grid_import': 0,\n",
    "                                'grid_export': max(0,pv-load-p_char),#abs(min(load-pv,0)),\n",
    "                                'pv_consummed': min(pv, load+p_char),\n",
    "                                'genset':1,\n",
    "                           }\n",
    "\n",
    "        building_data = building.run(control_dict)\n",
    "        total_building_cost.append(building.get_cost())\n",
    "    \n",
    "    return total_building_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import the Gym environnement with finite States & Actions\n",
    "import DiscreteEnvironment1 as DiscreteEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction qui initie la qtable, notre qtable comporte une variable d'état de plus : le prix de l'electricité\n",
    "def init_qtable(env, nb_action):\n",
    "    \n",
    "    state = []\n",
    "    Q = {}\n",
    "\n",
    "    for i in range(-int(env.mg.parameters['PV_rated_power']-1),int(env.mg.parameters['load']+2)):\n",
    "        \n",
    "        for k in np.arange(round(env.mg.battery.soc_min,1),round(env.mg.battery.soc_max+0.1,1),0.1):\n",
    "            for price in ['cheap', 'expensive']:\n",
    "            \n",
    "                k = round(k,1)\n",
    "                state.append((i,k,price))\n",
    "            #set_trace()\n",
    "\n",
    "    #Initialize Q(s,a) at zero\n",
    "    for s in state:\n",
    "\n",
    "        Q[s] = {}\n",
    "\n",
    "        for a in range(nb_action):\n",
    "\n",
    "            Q[s][a] = 0\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction décidant de l'action à suivre : aléatoire ou l'action optimal selon la qtable\n",
    "def espilon_decreasing_greedy(action, epsilon, nb_action):\n",
    "    \n",
    "    p = np.random.random()\n",
    "\n",
    "    if p < (1 - epsilon):\n",
    "        randomm=0\n",
    "        return action, randomm\n",
    "\n",
    "    else: \n",
    "        randomm=1\n",
    "        return np.random.choice(nb_action), randomm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction argmax de la qtable\n",
    "def max_dict(d):\n",
    "# fonction ajustant l'exploration\n",
    "\n",
    "    max_key = None\n",
    "    max_val = float('-inf')\n",
    "\n",
    "\n",
    "    for k,v in d.items():\n",
    "\n",
    "        if v > max_val:\n",
    "\n",
    "            max_val = v\n",
    "            max_key = k\n",
    "\n",
    "    return max_key, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction renvoyant la moyenne glissante sur une semaine du coût \n",
    "def moyenne_glissante(cost):\n",
    "    mg = []\n",
    "    interval = 24*7\n",
    "    for i in range(len(cost)-interval):\n",
    "        mg.append(np.mean(cost[i:i+interval]))\n",
    "    return np.array(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction ajustant l'exploration\n",
    "def update_epsilon(epsilon):\n",
    "    \n",
    "    epsilon = epsilon - epsilon *0.02\n",
    "    \n",
    "    if epsilon < 0.1:\n",
    "        \n",
    "        epsilon = 0.1\n",
    "    \n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_welcome(idx):\n",
    "    \n",
    "    if idx == 0:\n",
    "        print(\"------------------------------------\")\n",
    "        print(\"|        WELCOME TO PYMGRID        |\")\n",
    "        print(\"------------------------------------\")\n",
    "    elif idx == 1:\n",
    "        \n",
    "        print(\"t -     STATE  -  ACTION - COST\")\n",
    "        print(\"================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construction des qtables \n",
    "def training(mg,horizon,nb_action = 5):\n",
    "    \n",
    "    env_config={'building':mg}\n",
    "    building_environment = DiscreteEnvironment.Environment(env_config)\n",
    "    \n",
    "    \n",
    "    Q = init_qtable(building_environment,nb_action)\n",
    "    #set_trace()\n",
    "    alpha = 0.2\n",
    "    nb_state = len(Q)\n",
    "    nb_episode = 100\n",
    "    epsilon = 0.99\n",
    "    gamma = 0.99\n",
    "    \n",
    "    record_cost = []\n",
    "    t0 = time.time()\n",
    "    t = t0\n",
    "    print_training = \"Training Progressing .   \"\n",
    "    print_welcome(0)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    for e in range(nb_episode+1):\n",
    "        #alpha = update_alpha(e,nb_episode)\n",
    "        \n",
    "        if e == 0:\n",
    "            value_print=\"\\rEpisode \" + str(e) +\"/\" + str(nb_episode)\n",
    "            sys.stdout.write(value_print)\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            now = time.time()\n",
    "            \n",
    "            if e == 1 or e == 50 or e == 100 or e == 200 or e == 300 or e == 400  or e == 450  or e == 485 or e == nb_episode-5:\n",
    "                diff_time_t = now - t \n",
    "                total_time = (nb_episode+1) * diff_time_t\n",
    "            \n",
    "            now = time.time()\n",
    "            \n",
    "            diff_time = now - t0\n",
    "            time_remaining = total_time - diff_time\n",
    "            \n",
    "            t = time.time()\n",
    "        \n",
    "        if e % 10 == 0:\n",
    "        \n",
    "            if print_training == \"Training Progressing .   \":\n",
    "                \n",
    "                print_training = \"Training Progressing ..  \"\n",
    "                \n",
    "            elif print_training == \"Training Progressing ..  \":\n",
    "            \n",
    "                print_training = \"Training Progressing ... \"\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                print_training = \"Training Progressing .   \"\n",
    "\n",
    "        value_print=\"\\r\"+ print_training +\"Episode \" + str(e) +\"/\" + str(nb_episode) \n",
    "        sys.stdout.write(value_print)\n",
    "        sys.stdout.flush()\n",
    "            \n",
    "        episode_cost = 0\n",
    "        mg.reset()    \n",
    "        \n",
    "        net_load = round(mg.load - mg.pv)\n",
    "        soc = round(mg.battery.soc,1)\n",
    "        if mg.grid.price_import > 0.3:\n",
    "            price = 'expensive'\n",
    "        else:\n",
    "            price = 'cheap'\n",
    "        \n",
    "       # set_trace()\n",
    "        \n",
    "        s = (net_load, soc, price)\n",
    "\n",
    "        a = max_dict(Q[s])[0]\n",
    "        a,randomm = espilon_decreasing_greedy(a, epsilon, nb_action)\n",
    "\n",
    "        for i in range (horizon):\n",
    "\n",
    "                s_,r,done,info=building_environment.step(a)\n",
    "                #if building_environment.mg.get_co2()>0:\n",
    "                #    set_trace()\n",
    "                \n",
    "                #r = (-building_environment.mg.get_co2() + r)/2\n",
    "                episode_cost += r\n",
    "                if building_environment.mg.grid.price_import > 0.3:\n",
    "                    s_ = (s_[0],s_[1],'expensive')\n",
    "                else : \n",
    "                    s_ = (s_[0],s_[1],'cheap')\n",
    "                #s_ = (s_[0],s_[1],price)\n",
    "                #set_trace()\n",
    "                a_ = max_dict(Q[s_])[0]\n",
    "                #a_ = a\n",
    "\n",
    "                if i == horizon-1:\n",
    "\n",
    "                    Q[s][a] += alpha*(r - Q[s][a])\n",
    "\n",
    "                else:\n",
    "\n",
    "                    old_Q = Q[s][a]\n",
    "                    target = r + gamma*Q[s_][a_]\n",
    "                    td_error = target - Q[s][a]\n",
    "                    Q[s][a] = (1-alpha) * Q[s][a] + alpha * td_error\n",
    "                    #Q[s][a] = Q[s][a] + alpha * ((r + gamma*Q[s_][a]) - Q[s][a])\n",
    "\n",
    "                s, a = s_, a_\n",
    "\n",
    "        epsilon = update_epsilon(epsilon)\n",
    "        \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction executant tout les pas de temps sur une semaine en suivant les règles basiques pour le batiment passé en argument\n",
    "def naive_rule_for_1_week(building):\n",
    "    \n",
    "    building_data = building.get_updated_values()\n",
    "\n",
    "    total_building_cost = 0\n",
    "    total_building_co2 = 0\n",
    "    for i in range(24*7):\n",
    "        load = building_data['load']\n",
    "        pv = building_data['pv']\n",
    "        capa_to_charge = building_data['capa_to_charge']\n",
    "        capa_to_dischare = building_data['capa_to_discharge']\n",
    "\n",
    "        p_disc = max(0, min(load-pv, capa_to_dischare, building.battery.p_discharge_max))\n",
    "        p_char = max(0, min(pv-load, capa_to_charge, building.battery.p_charge_max))\n",
    "\n",
    "        if load - pv >=  0:\n",
    "\n",
    "            control_dict = {'battery_charge': 0,\n",
    "                                'battery_discharge': p_disc,\n",
    "                                'grid_import': max(0, load-pv-p_disc),\n",
    "                                'grid_export':0,\n",
    "                                'pv_consummed': min(pv, load),\n",
    "                                'genset':1,\n",
    "                           }\n",
    "\n",
    "\n",
    "        if load - pv <  0:\n",
    "\n",
    "            control_dict = {'battery_charge': p_char,\n",
    "                                'battery_discharge': 0,\n",
    "                                'grid_import': 0,\n",
    "                                'grid_export': max(0,pv-load-p_char),#abs(min(load-pv,0)),\n",
    "                                'pv_consummed': min(pv, load+p_char),\n",
    "                                'genset':1,\n",
    "                           }\n",
    "\n",
    "        building_data = building.run(control_dict)\n",
    "        total_building_cost += building.get_cost()\n",
    "        i+=1\n",
    "    \n",
    "    return total_building_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[0].reset()\n",
    "buildings[1].reset()\n",
    "buildings[2].reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "train_start = time.process_time()\n",
    "Q1=training(buildings[0],int(8736))\n",
    "Q2=training(buildings[1],8736,5)\n",
    "Q3=training(buildings[2],8736,7)\n",
    "train_end = time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_environments = [\n",
    "    DiscreteEnvironment.Environment(env_config={'building':buildings[i]}) for i in range(3)\n",
    "]\n",
    "Q=[Q1,Q2,Q3]\n",
    "test_start2 = time.process_time()\n",
    "\n",
    "tab_cost_Qlr = [[],[],[]]\n",
    "\n",
    "for i,building_env in enumerate(building_environments):\n",
    "    \n",
    "    obs = building_env.reset(testing=False)\n",
    "    obs = (obs[0],obs[1],'cheap')\n",
    "    done = False\n",
    "    while not done:\n",
    "        action=max_dict(Q[i][obs])[0]\n",
    "\n",
    "        obs, reward, done, info = building_env.step(action)\n",
    "        if building_env.mg.grid.price_import > 0.3:\n",
    "            obs = (obs[0],obs[1],'expensive')\n",
    "        else : \n",
    "            obs = (obs[0],obs[1],'cheap')\n",
    "        tab_cost_Qlr[i].append(reward)\n",
    "\n",
    "test_end2 = time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = []\n",
    "for i in range(3):\n",
    "    buildings[i].reset(testing = False)\n",
    "    cost.append(naive_rule_based_strategy(buildings[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start = time.process_time()\n",
    "\n",
    "building_environments = [\n",
    "    DiscreteEnvironment.Environment(env_config={'building':buildings[i]}) for i in range(3)\n",
    "]\n",
    "Q=[Q1,Q2,Q3]\n",
    "total_cost = [0,0,0]\n",
    "total_co2 = [0,0,0]\n",
    "\n",
    "cost = np.array(cost)\n",
    "\n",
    "for i,building_env in enumerate(building_environments):\n",
    "    hour = 0\n",
    "    \n",
    "    tab_cost_Qlr[i] = [-i for i in tab_cost_Qlr[i]]\n",
    "    \n",
    "    indice_to_switch = np.where(moyenne_glissante(cost[i]) < moyenne_glissante(tab_cost_Qlr[i]))\n",
    "\n",
    "    \n",
    "    obs = building_env.reset(testing=True)\n",
    "    obs = (obs[0],obs[1],'cheap')\n",
    "    done = False\n",
    "    while not done:\n",
    "        if hour in indice_to_switch[0]:\n",
    "            total_cost[i]+= naive_rule_for_1_week(building_env.mg)\n",
    "            hour += 24*7\n",
    "            \n",
    "        else:\n",
    "            hour +=1\n",
    "            action=max_dict(Q[i][obs])[0]\n",
    "            obs, reward, done, info = building_env.step(action)\n",
    "            if building_env.mg.grid.price_import > 0.3:\n",
    "                obs = (obs[0],obs[1],'expensive')\n",
    "            else : \n",
    "                obs = (obs[0],obs[1],'cheap')\n",
    "\n",
    "            total_cost[i]+=reward\n",
    "            total_co2[i]+=building_env.mg.get_co2()\n",
    "\n",
    "test_end = time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_cost *=-1\n",
    "total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frug = train_end + test_end +test_end2 - (train_start + test_start +test_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {\n",
    "    \"building_1_performance\" : -total_cost[0],\n",
    "    \"building_2_performance\" : -total_cost[1],\n",
    "    \"building_3_performance\" : -total_cost[2],\n",
    "    \"frugality\" : frug,\n",
    "}\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'implémentation d'un algo hybride nous a été motivé par le graphique ci-dessous, on constate bien que pour certaine semaine (notament en fin d'année) le qlearning est bien moins efficace que des règles tout à fait basique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(moyenne_glissante(cost_plot) < moyenne_glissante(tab_cost_Qlr_plot))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "hiparis",
   "language": "python",
   "name": "hiparis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
