{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/Total-RD/pymgrid/\n",
    "#!pip install tensorforce\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pymgrid.Environments.pymgrid_cspla import MicroGridEnv\n",
    "from tensorforce.environments import Environment\n",
    "import tensorforce\n",
    "from tensorforce.agents import Agent\n",
    "from tensorforce.execution import Runner\n",
    "import time\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\"\"\"\n",
    "The buildings mentionned below are specific to the hackathon and are not available in this repo.\n",
    "You can replace them with any MicroGrid object generated from pymgrid\n",
    "\"\"\"\n",
    "\n",
    "with open('building_1.pkl', 'rb') as f:\n",
    "    building_1 = pickle.load(f)\n",
    "    building_1.train_test_split()\n",
    "\n",
    "with open('building_2.pkl', 'rb') as f:\n",
    "    building_2 = pickle.load(f)\n",
    "    building_2.train_test_split()\n",
    "    \n",
    "with open('building_3.pkl', 'rb') as f:\n",
    "    building_3 = pickle.load(f)\n",
    "    building_3.train_test_split()\n",
    "\n",
    "buildings = [building_1, building_2, building_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train DeepRL model and test it --> with Tensorforce\n",
    "## We will train our model on the building 3, and after test it on all the buildings\n",
    "\n",
    "def train_test_deepRL():\n",
    "    building_environment_train = MicroGridEnv(env_config={'microgrid':buildings[2],\"testing\":False})\n",
    "    \n",
    "    #Best init values :\n",
    "    nb_hours = 5846\n",
    "    learning_rate = 1e-2\n",
    "    horizon = 1\n",
    "    nb_episodes = 2\n",
    "    \n",
    "    #Creating Tensorforce environment and agent\n",
    "    environment = Environment.create(\n",
    "    environment=building_environment_train, max_episode_timesteps=nb_hours)\n",
    "\n",
    "    agent = Agent.create(\n",
    "        agent='tensorforce', environment=environment, update=64,\n",
    "        optimizer=dict(optimizer='adam', learning_rate=learning_rate),\n",
    "        objective='policy_gradient', reward_estimation=dict(horizon=horizon))\n",
    "    \n",
    "    \n",
    "    # Training model :\n",
    "    print(\"Begining training...\")\n",
    "    train_start = time.process_time()\n",
    "\n",
    "    for _ in range(nb_episodes):\n",
    "        states = environment.reset()\n",
    "        terminal = False\n",
    "        l_rewards = []\n",
    "        i = 0\n",
    "        while not terminal:\n",
    "            actions = agent.act(states=states)\n",
    "            states, terminal, reward = environment.execute(actions=actions)\n",
    "            agent.observe(terminal=terminal, reward=reward)\n",
    "            i+=1\n",
    "            if i>200:\n",
    "                break\n",
    "\n",
    "    train_end = time.process_time()\n",
    "    train_frugality = train_end - train_start\n",
    "    print(\"Finished training.\")\n",
    "    \n",
    "    \n",
    "    #Testing on the 3 buildings :\n",
    "    list_cost, list_frugality_test = [], []\n",
    "    building_env_test = [MicroGridEnv(env_config={'microgrid':buildings[i],\"testing\":True}) for i in range(3)]\n",
    "    \n",
    "    for building_env in building_env_test :\n",
    "        test_start = time.process_time()\n",
    "        reward = 0\n",
    "        l_rewards = []\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.act(states, deterministic=True, independent=True)\n",
    "            states, reward, done, info = building_env.step(action)\n",
    "            l_rewards.append(-reward)\n",
    "\n",
    "        cost = np.sum(l_rewards)\n",
    "        test_end = time.process_time()\n",
    "        \n",
    "        list_cost.append(cost)\n",
    "        test_frugality = test_end - test_start\n",
    "        list_frugality_test.append(test_frugality)\n",
    "        \n",
    "    frugality = np.sum(list_frugality_test) + train_frugality\n",
    "    \n",
    "    \n",
    "    return(list_cost, frugality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cost, frugality = train_test_deepRL()\n",
    "cost1, cost2, cost3 = list_cost\n",
    "\n",
    "print(\"TEST COSTS :\", list_cost)\n",
    "print(\"Total frugality:\", frugality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-australian",
   "metadata": {},
   "source": [
    "**Saving results :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {\n",
    "    \"building_1_performance\" : cost1,\n",
    "    \"building_2_performance\" : cost2,\n",
    "    \"building_3_performance\" : cost3,\n",
    "    \"frugality\" : frugality,\n",
    "}\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-threat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "hiparis",
   "language": "python",
   "name": "hiparis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
